{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw----+ 1 root video 81, 1 Aug 28 16:18 /dev/video1\n",
      "crw-rw----+ 1 root video 81, 2 Aug 28 16:18 /dev/video2\n"
     ]
    }
   ],
   "source": [
    "# Check device number\n",
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0 cuda: True\n",
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.187 🚀 Python-3.10.12 torch-2.8.0 CUDA:0 (Orin, 7620MiB)\n",
      "YOLO11n-pose summary (fused): 109 layers, 2,956,000 parameters, 0 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 68, 8400) (6.0 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnxruntime-gpu\" ' returned non-zero exit status 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnxruntime-gpu\" ' returned non-zero exit status 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: No matching distribution found for onnxruntime-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache-dir \"onnxruntime-gpu\" ' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.59...\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: module 'onnx.helper' has no attribute 'get_all_tensor_dtypes'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 8.4s, saved as 'yolo.onnx' (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "[08/28/2025-16:30:27] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 749, GPU 4510 (MiB)\n",
      "[08/28/2025-16:30:30] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +928, GPU +1075, now: CPU 1720, GPU 5621 (MiB)\n",
      "[08/28/2025-16:30:30] [TRT] [I] ----------------------------------------------------------------\n",
      "[08/28/2025-16:30:30] [TRT] [I] Input filename:   yolo.onnx\n",
      "[08/28/2025-16:30:30] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[08/28/2025-16:30:30] [TRT] [I] Opset version:    19\n",
      "[08/28/2025-16:30:30] [TRT] [I] Producer name:    pytorch\n",
      "[08/28/2025-16:30:30] [TRT] [I] Producer version: 2.8.0\n",
      "[08/28/2025-16:30:30] [TRT] [I] Domain:           \n",
      "[08/28/2025-16:30:30] [TRT] [I] Model version:    0\n",
      "[08/28/2025-16:30:30] [TRT] [I] Doc string:       \n",
      "[08/28/2025-16:30:30] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 68, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolo.engine\n",
      "[08/28/2025-16:30:30] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[08/28/2025-16:35:01] [TRT] [I] [GraphReduction] The approximate region cut reduction algorithm is called.\n",
      "[08/28/2025-16:35:01] [TRT] [I] Detected 1 inputs and 4 output network tensors.\n",
      "[08/28/2025-16:35:05] [TRT] [I] Total Host Persistent Memory: 593536\n",
      "[08/28/2025-16:35:05] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[08/28/2025-16:35:05] [TRT] [I] Total Scratch Memory: 2764800\n",
      "[08/28/2025-16:35:05] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 269 steps to complete.\n",
      "[08/28/2025-16:35:05] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 47.8858ms to assign 12 blocks to 269 nodes requiring 20959232 bytes.\n",
      "[08/28/2025-16:35:05] [TRT] [I] Total Activation Memory: 20958720\n",
      "[08/28/2025-16:35:05] [TRT] [I] Total Weights Memory: 12035332\n",
      "[08/28/2025-16:35:05] [TRT] [I] Engine generation completed in 274.809 seconds.\n",
      "[08/28/2025-16:35:05] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 132 MiB\n",
      "[08/28/2025-16:35:05] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 2580 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 287.7s, saved as 'yolo.engine' (13.8 MB)\n",
      "\n",
      "Export complete (289.7s)\n",
      "Results saved to \u001b[1m/home/wonmin/project/hand_keypoints/yolo_inference\u001b[0m\n",
      "Predict:         yolo predict task=pose model=yolo.engine imgsz=640  \n",
      "Validate:        yolo val task=pose model=yolo.engine imgsz=640 data=/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/hand-keypoints.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "print(torch.__version__, \"cuda:\", torch.cuda.is_available())\n",
    "\n",
    "#make ft32 tensorrt file\n",
    "model = YOLO(\"yolo.pt\", task=\"pose\")    # 또는 task=\"detect\"\n",
    "model.export(format=\"engine\")\n",
    "\n",
    "os.rename(\"yolo.engine\", \"yolo_fp32.engine\")\n",
    "os.rename(\"yolo.onnx\", \"yolo_fp32.engine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://172.30.1.50:8000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yolo_fp32.engine for TensorRT inference...\n",
      "[ERROR ❌ TensorRT model exported with a different version than 10.3.0\n",
      "\n",
      "08/28/2025-16:38:28] [TRT] [I] Loaded engine size: 11 MiB\n",
      "[08/28/2025-16:38:28] [TRT] [E] IRuntime::deserializeCudaEngine: Error Code 1: Serialization (Serialization assertion plan->header.magicTag == rt::kPLAN_MAGIC_TAG failed.Trying to load an engine created with incompatible serialization version. Check that the engine was not created using safety runtime, same OS was used and version compatibility parameters were set accordingly.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.93 - - [28/Aug/2025 16:38:28] \"GET / HTTP/1.1\" 500 -\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wonmin/project/hand_keypoints/venv/lib/python3.10/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/home/wonmin/project/hand_keypoints/venv/lib/python3.10/site-packages/werkzeug/serving.py\", line 333, in execute\n",
      "    for data in application_iter:\n",
      "  File \"/home/wonmin/project/hand_keypoints/venv/lib/python3.10/site-packages/werkzeug/wsgi.py\", line 256, in __next__\n",
      "    return self._next()\n",
      "  File \"/home/wonmin/project/hand_keypoints/venv/lib/python3.10/site-packages/werkzeug/wrappers/response.py\", line 32, in _iter_encoded\n",
      "    for item in iterable:\n",
      "  File \"/tmp/ipykernel_49439/3885305649.py\", line 22, in gen_frames\n",
      "    results = model.predict(source=frame, imgsz=640, verbose=False)\n",
      "  File \"/home/wonmin/.local/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 548, in predict\n",
      "    self.predictor.setup_model(model=self.model, verbose=is_cli)\n",
      "  File \"/home/wonmin/.local/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 391, in setup_model\n",
      "    self.model = AutoBackend(\n",
      "  File \"/home/wonmin/project/hand_keypoints/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/wonmin/.local/lib/python3.10/site-packages/ultralytics/nn/autobackend.py\", line 366, in __init__\n",
      "    raise e\n",
      "  File \"/home/wonmin/.local/lib/python3.10/site-packages/ultralytics/nn/autobackend.py\", line 363, in __init__\n",
      "    context = model.create_execution_context()\n",
      "AttributeError: 'NoneType' object has no attribute 'create_execution_context'\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# YOLO 모델 불러오기 (best.pt or .engine 가능)\n",
    "model = YOLO(\"yolo_fp32.engine\", task=\"pose\")\n",
    "\n",
    "c_index = 1 #Camera index can be changed\n",
    "\n",
    "cap = cv2.VideoCapture(c_index) \n",
    "assert cap.isOpened(), \"Camera open failed.\"\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def gen_frames():\n",
    "    while True:\n",
    "        ret, frame = cap.read() \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # YOLO inference\n",
    "        results = model.predict(source=frame, imgsz=640, verbose=False)\n",
    "        annotated = results[0].plot()  # draw inference results\n",
    "\n",
    "        # JPEG encoding\n",
    "        ret, buffer = cv2.imencode('.jpg', annotated)\n",
    "        if not ret:\n",
    "            continue #If encoding is failed, skip\n",
    "\n",
    "        # MJPEG streaming: MJPEG = Motion JPEG\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + buffer.tobytes() + b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def video_feed():\n",
    "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        app.run(host=\"0.0.0.0\", port=8000, debug=False, use_reloader=False)\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
